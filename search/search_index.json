{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is <code>SableDb</code>?","text":"<p><code>SableDb</code> is a key-value NoSQL database that utilizes <code>RocksDb</code> as its storage engine and is compatible with the Redis protocol. It aims to reduce memory costs and increase capacity compared to Redis. <code>SableDb</code> features include Redis-compatible access via  any Redis client, up to 64K databases support, asynchronous replication using transaction log tailing and TLS connectivity support.</p>"},{"location":"design/overview/","title":"High Level Design","text":""},{"location":"design/overview/#overview","title":"Overview","text":"<p>This chapter covers the overall design choices made for building <code>SableDb</code>.</p> <p>The networking layer of SableDb uses a lock free design. i.e. once a connection is assigned to a worker thread it does not interact with any other threads or shared data structures.</p> <p>Having said that, there is one obvious \"point\" that requires locking: the storage.  The current implementation of <code>SableDb</code> uses <code>RocksDb</code> as its storage engine  (but it can, in principal, work with other storage engines like <code>Sled</code>), even though the the storage itself is thread-safe, <code>SableDb</code> still needs to provide atomicity for multiple database access (consider the <code>ValKey</code>'s <code>getset</code> command which requires to perform both <code>get</code> and <code>set</code> in a single operation) - <code>SableDb</code> achieves this by using a shard locking (more details on this later).</p> <p>By default, <code>SableDb</code> listens on port <code>6379</code> for incoming connections. A newly arrived connection is then assigned to a worker thread (using simple round-robin method). The worker thread spawns a local task (A task, is tokio's implementation for green threads) which performs the TLS handshake (if dictated by the configuration) and then splits the connection stream into two: </p> <ul> <li>Reader end</li> <li>Writer end</li> </ul> <p>Each end of the stream is then passed into a dedicated local task for handling</p>"},{"location":"design/overview/#the-reader-task","title":"The reader task","text":"<p>The reader task is responsible for:</p> <ul> <li>Reading bytes from the stream </li> <li>Parsing the incoming message and forming a <code>RedisCommand</code> structure</li> <li>Once a full command is read from the socket, it is moved to the writer task</li> </ul>"},{"location":"design/overview/#the-writer-task","title":"The writer task","text":"<p>The writer task input are the commands read and constructed by the reader task.</p> <p>Once a command is received, the writer task invokes the proper handler for that command (if the command it not supported an error message is sent back to the client). </p> <p>As an output, the handler of the command can either build a response buffer to send over to the client or send the response directly.</p> <p>The decision whether to reply directly or propagate the response to the caller task is done on per command basis.</p> <p>For example, the <code>hgetall</code> command might generate a huge output (depends on the number of fields in the hash and their size) so it is probably better to write the response directly to the socket (using a controlled fixed chunks) rather than building  a complete response in memory (which can take Gigabytes of RAM) and only then write it to the client.</p>"},{"location":"design/replication/","title":"Replication","text":""},{"location":"design/replication/#overview","title":"Overview","text":"<p><code>SableDb</code> supports a <code>1</code> : <code>N</code> replication (single primary -&gt; multiple replicas) configuration.</p> <p>The primary server is stateless i.e. it does not keep track of its replicas. It is up to replica server to pull data from the primary and to keep track of the next change sequence ID to pull.</p> <p>In case there are no changes to send over, the primary server delays the response until something is available to send over to the replica</p> <p>The Primary &lt;-&gt; Replica is built using <code>RocksDb</code> APIs: <code>create_checkpoint</code> and <code>get_updates_since</code>.</p> <p>In addition, <code>SableDb</code> maintains a file named <code>changes.seq</code> inside the database folder which holds the next transaction ID that should be pulled from the primary.</p> <p>The below sequence of events describes the data flow between the replica and the primary:</p> <p></p> <p>When a fullsync is needed, the flow changes to this:</p> <p></p>"}]}