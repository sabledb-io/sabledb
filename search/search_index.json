{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is <code>SableDB</code>?","text":"<p><code>SableDB</code> is a key-value NoSQL database that utilizes <code>RocksDB</code> as its storage engine and is compatible with the Redis protocol. It aims to reduce memory costs and increase capacity compared to Redis. <code>SableDB</code> features include Redis-compatible access via any Redis client, up to 64K databases support, asynchronous replication using transaction log tailing and TLS connectivity support.</p>"},{"location":"design/auto-failover/","title":"Automatic Shard Management","text":""},{"location":"design/auto-failover/#terminology","title":"Terminology","text":"<p><code>Shard</code> - a hierarchical arrangement of nodes. Within a shard, one node functions as the read/write Primary node. While all the nodes are a read-only replicas of the primary node.</p> <p><code>SableDB</code> uses a centralised database to manage an auto-failover process and tracking nodes of the same shard. The centralised database itself is an instance of <code>SableDB</code>.</p>"},{"location":"design/auto-failover/#all-nodes","title":"All Nodes","text":"<p>Every node in the shard, updates a record of type <code>HASH</code> every <code>N</code> seconds in the centralised database where it keeps the following hash fields:</p> <ul> <li><code>node_id</code> this is a globally unique ID assigned to each node when it first started and it persists throughout restarts</li> <li><code>node_address</code> the node privata address on which other nodes can connect to it</li> <li><code>role</code> the node role (can be one <code>replica</code> or <code>primary</code>)</li> <li><code>last_updated</code> the last time that this node updated its information, this field is a UNIX timestamp since Jan 1st, 1970 in microseconds. This field is also used as the \"heartbeat\" of node</li> <li><code>last_txn_id</code> contains the last transaction ID applied to the local data set. In an ideal world, this number is the same across all instances of the shard. The higher the number, the more up-to-date the node is</li> <li><code>primary_node_id</code> if the <code>role</code> field is set to <code>replica</code>, this field contains the <code>node_id</code> of the shard primary node.</li> </ul> <p>The key used for this <code>HASH</code> record, is the node-id</p>"},{"location":"design/auto-failover/#primary","title":"Primary","text":"<p>In addition for updating its own record, the primary node maintains an entry of type <code>SET</code> which holds the <code>node_id</code>s of all the shard node members.</p> <p>This <code>SET</code> is constantly updated whenever the primary interacts with a replica node. Only after the replica node successfully completes a FullSyc, it can be added to this <code>SET</code>.</p> <p>This <code>SET</code> entry is identified by the key <code>&lt;primary_id&gt;_replicas</code> where <code>&lt;primary_id&gt;</code> is the primary node unique id.</p>"},{"location":"design/auto-failover/#replica","title":"Replica","text":"<p>Similar to the primary node, the replica updates its information in a regular intervals</p>"},{"location":"design/auto-failover/#auto-failover","title":"Auto-Failover","text":"<p>In order to detect whether the primary node is still alive, <code>SableDB</code> uses the Raft algorithm while using the centralised database as its communication layer and the <code>last_txn_id</code> as the log entry</p> <p>Each replica node regularly checks the <code>last_updated</code> field of the primary node the interval on which a replica node checks differs from node to node - this is to minimise the risk of attempting to start multiple failover processes (but this can still happen and is solved by the lock described blow)</p> <p>The failover process starts if the primary's <code>last_updated</code> was not updated after the allowed time. If the value exceeds, then the replica node does the following:</p>"},{"location":"design/auto-failover/#the-replica-that-initiated-the-failover","title":"The replica that initiated the failover","text":"<ul> <li>Marks in the centralised database that a failover is initiated for the non responsive primary</li> <li>The node that started the failover decides on the new primary. It does that by picking the one with the highest <code>last_txn_id</code> property</li> <li>Dispatches a command to the new selected node, instructing it to switch to Primary mode (we achieve this by using <code>LPUSH / BRPOP</code> blocking command)</li> <li>Dispatch commands to all of the remaining replicas instructing them to perform a <code>REPLICAOF &lt;NEW_PRIMARY_IP&gt; &lt;NEW_PRIMARY_PORT&gt;</code></li> <li>Delete the old primary records from the database (if this node comes back online again later, it will re-create them)</li> </ul>"},{"location":"design/auto-failover/#all-other-replicas","title":"All other replicas","text":"<p>Each replica node always checks for the shard's lock record. If it exists, each replica switches to waiting mode on a dedicated queue. This is achieved by using the below command:</p> <pre><code>BLPOP &lt;NODE_ID&gt;_queue 5\n</code></pre> <p>As mentioned above, there are 2 type of commands:</p> <ul> <li>Apply <code>REPLICAOF</code> to connect to the new primary</li> <li>Apply <code>REPLICAOF NO ONE</code> to become the new primary</li> </ul>"},{"location":"design/auto-failover/#a-note-about-locking","title":"A note about locking","text":"<p><code>SableDB</code> uses the command <code>SET &lt;PRIMARY_ID&gt;_FAILOVER &lt;Unique-Value&gt; NX EX 60</code> to create a unique lock. By doing so, it ensures that only one locking record exists. If it succeeded in creating the lock record, it becomes the node that orchestrates the replacement</p> <p>If it fails (i.e. the record already exist) - it switches to read commands from the queue as described here</p> <p>The only client allowed to delete the lock is the client created it, hence the <code>&lt;unique_value&gt;</code>. If that client crashed we have the <code>EX 60</code> as a backup plan (the lock will be expire)</p>"},{"location":"design/cluster/","title":"Cluster","text":""},{"location":"design/cluster/#understanding-the-sabledb-cluster","title":"Understanding the SableDB Cluster","text":"<p><code>SableDB</code> organizes its data into a distributed cluster using a system of slots and shards.</p>"},{"location":"design/cluster/#slots-data-distribution","title":"Slots: Data Distribution","text":"<p>Every key in <code>SableDB</code> is assigned a unique number between 0 and 16,383, determining its slot. Each node in the cluster is responsible for a specific range of these slots. If a client requests a key from a node that doesn't own its corresponding slot, the node returns a <code>MOVED</code> error, directing the client to the correct location.</p>"},{"location":"design/cluster/#shards-high-availability","title":"Shards: High Availability","text":"<p>A <code>SableDB</code> cluster is built from one or more shards. Each shard consists of a primary node and can optionally include multiple replicas for redundancy. Ideally, slots are evenly distributed among these shards, with each managing <code>16384 / K</code> slots in a cluster of <code>K</code> shards. This architecture can theoretically support up to 16,000 primary nodes, accommodating substantial workloads.</p>"},{"location":"design/cluster/#centralized-cluster-management","title":"Centralized Cluster Management","text":"<p><code>SableDB</code> employs a central database (itself a <code>SableDB</code> instance) to manage cluster communication and maintain its overall state. Each node periodically registers and updates its information (like owned slots and public address) in this central database, and also pulls information about other nodes from it.</p>"},{"location":"design/cluster/#flexible-slot-migration","title":"Flexible Slot Migration","text":"<p><code>SableDB</code> provides commands for transferring slot ownership between shards. For example, to move slot <code>1234</code> from <code>Node_1</code> to <code>Node_2</code>, you'd simply connect to <code>Node_1</code> via <code>sabledb-cli</code> and execute <code>SLOT SENDTO &lt;NODE_ID&gt; 1234</code>. The command returns <code>OK</code> upon successful completion.</p>"},{"location":"design/data-encoding/","title":"Overview","text":"<p><code>SableDB</code> uses a Key / Value database for its underlying data storage. We chose to use <code>RocksDB</code> as its mature, maintained and widely used in the industry by giant companies.</p> <p>Because the <code>RocksDB</code> is key-value storage and Redis data structures can be more complex, an additional data encoding is required.</p> <p>This chapter covers how <code>SableDB</code> encodes the data for the various data types (e.g. <code>String</code>, <code>Hash</code>, <code>Set</code> etc)</p> <p>Note</p> <p>Numbers are encoded using Big Endians to preserve lexicographic ordering</p> <p><code>SableDB</code> takes advantage of the following <code>RocksDB</code> traits:</p> <ul> <li><code>RocksDB</code> keys are stored lexicographically (this is why <code>SableDB</code> uses big-endiands)</li> <li><code>RocksDB</code> provides prefix iterators which allows <code>SableDB</code> to place iterator on the first item that matches a prefix</li> </ul>"},{"location":"design/data-encoding/#the-string-data-type","title":"The <code>String</code> data type","text":"<p>The most basic data type in <code>SableDB</code> is the <code>String</code> data type. <code>String</code>s in <code>SableDB</code> are always binary safe Each <code>String</code> record in the <code>SableDB</code> consists of a single entry in <code>RocksDB</code>:</p> <pre><code>   A    B      C      D                E        F       G     H\n+-----+-----+-------+----------+    +-----+------------+----+-------+\n| 1u8 | DB# | Slot# | user key | =&gt; | 0u8 | Expirtaion | ID | value |\n+-----+-----+-------+----------+    +-----+------------+----+-------+\n</code></pre> <p>The key for a <code>String</code> record is encoded as follows:</p> <ul> <li><code>A</code> the first byte ( <code>u8</code> ) is always set to <code>1</code> - this indicates that this is a data entry (there are other type of keys in the database)</li> <li><code>B</code> the database ID is encoded as <code>u16</code> (this implies that <code>SableDB</code> supports up to <code>64K</code> databases)</li> <li><code>C</code> the slot number</li> <li><code>D</code> the actual key value (e.g. <code>set mykey myvalue</code>  -&gt; <code>mykey</code> is set here)</li> </ul> <p>The value is encoded as follows:</p> <ul> <li><code>E</code> the first byte is the type bit, value of <code>0</code> means that the this record is of type <code>String</code></li> <li><code>F</code> the record expiration info</li> <li><code>G</code> unique ID (relevant for complex types like <code>Hash</code>), for <code>String</code> this is always <code>0</code></li> <li><code>H</code> the user value</li> </ul> <p>Using the above encoding, we can now understand how <code>SableDB</code> reads from the database. Lets have a look a the command:</p> <pre><code>get mykey\n</code></pre> <p><code>SableDB</code> encodes a key from the user key (<code>mykey</code>) by prepending the following:</p> <ul> <li><code>1</code>u8 - to indicate that this is the data record</li> <li>The active database number (defaults to <code>0</code>)</li> <li>The slot number</li> <li>The user string key (i.e. <code>mykey</code>)</li> </ul> <p>This is the key that is passed to <code>RocksDB</code> for reading - If the key exists in the database:     - If the type (field <code>E</code>) is <code>!= 0</code> - i.e. the entry is not a <code>String</code>, <code>SableDB</code> returns a <code>-WRONGTYPE</code> error     - If value is expired -&gt; <code>SableDB</code> returns <code>null</code> and deletes the record from the database     - Otherwise, <code>SableDB</code> returns the <code>H</code> part of the value (the actual user data) - Else (no such key) return <code>null</code></p>"},{"location":"design/data-encoding/#the-list-data-type","title":"The <code>List</code> data type","text":"<p>A <code>List</code> is a composite data type. <code>SableDB</code> stores the metadata of the list using a dedicated record and each list element is stored in a separate entry.</p> <pre><code>List metadata:\n\n   A    B       C        D\n+-----+---- +--------+------------+\n| 1u8 | DB# |  Slot# |  list name |\n+-----+---- +--------+------------+\n                             E        F        G        H      I       J\n                        +-----+------------+--------- +------+------+-------+\n                   =&gt;   | 1u8 | Expirtaion | List UID | head | tail |  size |\n                        +-----+------------+--------- +------+------+-------+\n\nList item:\n\n   K        L              M                 N      O           P\n+-----+--------------+---------------+    +------+--------+------------+\n| 2u8 | List ID(u64) |  Item ID(u64) | =&gt; | Left | Right  |     value  |\n+-----+--------------+---------------+    +------+--------+------------+\n</code></pre> <p>Unlike <code>String</code>, a <code>List</code> is using an additional entry in the database that holds the list metadata.</p> <ul> <li>Encoded items <code>A</code> -&gt; <code>D</code> are the same as <code>String</code></li> <li><code>E</code> the first byte is always set to <code>1</code> (unlike <code>String</code> which is set to <code>0</code>)</li> <li><code>F</code> Expiration info</li> <li><code>G</code> The list UID. Each list is assigned with a unique ID (an incremental number that never repeat itself, evern after restarts)</li> <li><code>H</code> the UID of the list head item (<code>u64</code>)</li> <li><code>I</code> the UID of the list tail item (<code>u64</code>)</li> <li><code>J</code> the list length</li> </ul> <p>In addition to the list metadata (<code>SableDB</code> keeps a single metadata item per list) we add a list item per new list item using the following encoding:</p> <ul> <li><code>K</code> the first bit which is always set to <code>2</code> (\"List Item\")</li> <li><code>L</code> the parent list ID (see field <code>G</code> above)</li> <li><code>M</code> the item UID</li> <li><code>N</code> the UID of the previous item in the list ( <code>0</code> means that this item is the head)</li> <li><code>O</code> the UID of the next item in the list ( <code>0</code> means that this item is the last item)</li> <li><code>P</code> the list value</li> </ul> <p>The above encoding allows <code>SableDB</code> to iterate over all list items by creating a <code>RocksDB</code> iterator and move it to the prefix <code>[ 2 | &lt;list-id&gt;]</code> (<code>2</code> indicates that only list items should be scanned, and <code>list-id</code> makes sure that only the requested list items are visited)</p>"},{"location":"design/data-encoding/#the-hash-data-type","title":"The <code>Hash</code> data type","text":"<p>Hash items are encoded using the following:</p> <pre><code>Hash metadata:\n\n   A    B       C        D                E        F        G         H\n+-----+---- +--------+-----------+    +-----+------------+---------+-------+\n| 1u8 | DB# |  Slot# | Hash name | =&gt; | 2u8 | Expirtaion | Set UID |  size |\n+-----+---- +--------+-----------+    +-----+------------+---------+-------+\n\nHash item:\n\n   P        Q           R           S\n+-----+--------------+-------+    +-------+\n| 3u8 | Hash ID(u64) | field | =&gt; | value |\n+-----+--------------+-------+    +-------+\n</code></pre> <ul> <li>Encoded items <code>A</code> -&gt; <code>H</code> are basically identical to the hash <code>A</code> -&gt; <code>H</code> fields</li> <li><code>P</code> always set to <code>3</code> (\"hash member\")</li> <li><code>Q</code> the hash ID for which this member belongs to</li> <li><code>R</code> the hash field</li> <li><code>S</code> the field's value</li> </ul>"},{"location":"design/data-encoding/#the-sorted-set-data-type","title":"The <code>Sorted Set</code> data type","text":"<p>The sorted set ( <code>Z*</code> commands) is encoded using the following:</p> <pre><code>Sorted set metadata:\n\n   A    B       C        D                E        F        G         H\n+-----+---- +--------+-----------+    +-----+------------+---------+-------+\n| 1u8 | DB# |  Slot# | ZSet name | =&gt; | 3u8 | Expirtaion | ZSet UID|  size |\n+-----+---- +--------+-----------+    +-----+------------+---------+-------+\n\nZSet item 1 (Index: \"Find by member\"):\n\n   K        L              M           O\n+-----+--------------+---------+    +-------+\n| 4u8 | ZSet ID(u64) |  member | =&gt; | score |\n+-----+--------------+---------+    +-------+\n\nZSet item 2 (Index: \"Find by score\"):\n\n   P        Q           R       S            T\n+-----+--------------+-------+-------+    +------+\n| 5u8 | ZSet ID(u64) | score |member | =&gt; | null |\n+-----+--------------+-------+-------+    +------+\n</code></pre> <p>Sorted set requires double index (score &amp; member), this is why each zset item member is kept using 2 records.</p> <p>The zset metadata contains:</p> <ul> <li>Encoded items <code>A</code> -&gt; <code>D</code> are the same as <code>String</code></li> <li><code>E</code> will always contains <code>3</code> for <code>sorted set</code></li> <li><code>F</code> the expiration info</li> <li><code>G</code> the unique zset ID</li> <li><code>H</code> the set size (number of members)</li> </ul> <p>Each zset item are kept using 2 records:</p>"},{"location":"design/data-encoding/#index-find-by-member","title":"Index: \"Find by member\"","text":"<p>The first record allows <code>SableDB</code> to find a member score (the key is the member value)</p> <ul> <li><code>K</code> the first bit which is always set to <code>4</code> (\"ZSet member Item\")</li> <li><code>L</code> the zset ID for which this item belongs to</li> <li><code>M</code> the zset member</li> <li><code>O</code> this member score value</li> </ul>"},{"location":"design/data-encoding/#index-find-by-score","title":"Index: \"Find by score\"","text":"<p>The second record, allows <code>SableDB</code> to find member by score (we use the score as the key)</p> <ul> <li><code>P</code> the first bit is always set to <code>5</code> (\"Zset score item\")</li> <li><code>Q</code> the zset ID for which this item belongs to</li> <li><code>R</code> the record's score value</li> <li><code>S</code> the member</li> <li><code>T</code> not used</li> </ul> <p>The above encoding records provides all the indexing required by <code>SableDB</code> to implement the sorted set commands.</p> <p>For example, in order to implement the command <code>ZCOUNT</code> (Returns the number of elements in the sorted set at key with a score between min and max):</p> <ul> <li><code>SableDB</code> first loads the metadata using the zset key in order to obtain its unique ID</li> <li>Creates an iterator using the prefix <code>[5 | ZSET UID | MIN_SCORE]</code> (Index: \"Find by score\")</li> <li>Start iterating until it either finds the first entry that does not belong to the zset, or it finds the <code>MAX_SCORE</code> value</li> </ul>"},{"location":"design/data-encoding/#the-set-data-type","title":"The <code>Set</code> data type","text":"<p>Set items are encoded using the following:</p> <pre><code>Set metadata:\n\n   A    B       C        D                E        F        G         H\n+-----+---- +--------+-----------+    +-----+------------+---------+-------+\n| 1u8 | DB# |  Slot# | Set name  | =&gt; | 4u8 | Expirtaion | Set UID |  size |\n+-----+---- +--------+-----------+    +-----+------------+---------+-------+\n\nSet item:\n\n   P        Q           R           S\n+-----+--------------+-------+    +------+\n| 6u8 | Set ID(u64)  | field | =&gt; | null |\n+-----+--------------+-------+    +------+\n</code></pre> <ul> <li>Encoded items <code>A</code> -&gt; <code>H</code> are basically identical to the sorted set <code>A</code> -&gt; <code>H</code> fields</li> <li><code>P</code> always set to <code>6</code> (\"set member\")</li> <li><code>Q</code> the set ID for which this member belongs to</li> <li><code>R</code> the set field</li> <li><code>S</code> null (not used)</li> </ul>"},{"location":"design/data-encoding/#bookkeeping-records","title":"Bookkeeping records","text":"<p>Every composite item (<code>Hash</code>, <code>Sorted Set</code>, <code>List</code> or <code>Set</code>) created by <code>SableDB</code>, also creates a record in the <code>bookkeeping</code> \"table\". A bookkeeping records keeps track of the composite item unique ID + its type (which is needed by the data eviction job)</p> <p>The <code>bookkeeping</code> record is encoded as follows:</p> <pre><code>Bookkeeping:\n\n   A    B       C        D                E\n+-----+----+--------+-----------+    +----------+\n| 0u8 | UID|  DB#   | UID type  | =&gt; | user key |\n+-----+----+--------+-----------+    +----------+\n</code></pre> <ul> <li><code>A</code> a bookkeeping records starts with <code>0</code></li> <li><code>B</code> a <code>u64</code> field containing the composite item UID (e.g. <code>Hash UID</code>)</li> <li><code>C</code> the database ID for which the UID belongs to</li> <li><code>D</code> the UID type when it was created (e.g. \"hash\" or \"set\")</li> <li><code>E</code> the user key associated with the UID (e.g. the hash name)</li> </ul>"},{"location":"design/eviction/","title":"Data eviction","text":"<p>Data eviction in SableDB occurs in three primary scenarios:</p>"},{"location":"design/eviction/#expired-items","title":"Expired Items","text":"<p>SableDB stores data primarily on disk, a cost-effective solution. To manage expired items efficiently, SableDB checks an item's expiration status only when it's accessed. If an item is found to be expired, it's deleted, and a <code>null</code> value is returned to the caller.</p>"},{"location":"design/eviction/#overwritten-composite-items","title":"Overwritten Composite Items","text":"<p>A common issue arises when a composite item (like a Hash) is overwritten by a different data type. For instance, if you have a Hash named <code>OverwatchTanks</code> containing multiple fields (e.g. <code>tank_1</code>, <code>tank_2</code>, and <code>tank_3</code>), and then execute <code>SET OverwatchTanks \"bla\"</code>, the <code>OverwatchTanks</code> key becomes a String. However, as each Hash field is stored as a separate record in <code>RocksDB</code>, the original <code>tank_1</code>, <code>tank_2</code>, and <code>tank_3</code> fields become \"orphaned\" and inaccessible.</p> <p>SableDB addresses this with a background cron task. This task periodically compares the declared type of a composite item with its actual stored value. If a mismatch is detected (e.g., <code>OverwatchTanks</code> is now a String but still has associated Hash records), the cron job uses bookkeeping records to identify the original type and then deletes the orphaned records from the database.</p>"},{"location":"design/eviction/#user-triggered-cleanup","title":"User-Triggered Cleanup","text":"<p>When a user initiates a <code>FLUSHALL</code> or <code>FLUSHDB</code> command, SableDB leverages <code>RocksDB</code>'s <code>delete_range</code> method to efficiently purge the data.</p>"},{"location":"design/overview/","title":"High Level Design","text":""},{"location":"design/overview/#overview","title":"Overview","text":"<p>This chapter covers the overall design choices made when building <code>SableDB</code>.</p> <p>The networking layer of SableDB uses a lock free design. i.e. once a connection is assigned to a worker thread it does not interact with any other threads or shared data structures.</p> <p>Having said that, there is one obvious \"point\" that requires locking: the storage. The current implementation of <code>SableDB</code> uses <code>RocksDB</code> as its storage engine (but it can, in principal, work with other storage engines like <code>Sled</code>), even though the the storage itself is thread-safe, <code>SableDB</code> still needs to provide atomicity for multiple database access (consider the <code>ValKey</code>'s <code>getset</code> command which requires to perform both <code>get</code> and <code>set</code> in a single operation) - <code>SableDB</code> achieves this by using a shard locking (more details on this later).</p> <p>By default, <code>SableDB</code> listens on port <code>6379</code> for incoming connections. A newly arrived connection is then assigned to a worker thread (using simple round-robin method). The worker thread spawns a local task (A task, is tokio's implementation for green threads) which performs the TLS handshake (if dictated by the configuration) and then splits the connection stream into two:</p> <ul> <li>Reader end</li> <li>Writer end</li> </ul> <p>Each end of the stream is then passed into a newly spawned local task for handling</p> <p>Below is a diagram shows the main components within <code>SableDB</code>:</p> <p></p>"},{"location":"design/overview/#acceptor-thread","title":"Acceptor thread","text":"<p>The main thread of <code>SableDB</code> - after spawning the worker threads - is used as the TCP acceptor thread. Unless specified otherwise, <code>SableDB</code> listens on port 6379. Every incoming connection is moved to a thread for later handling so the acceptor can accept new connections</p>"},{"location":"design/overview/#tls-handshake","title":"TLS handshake","text":"<p>The worker thread moves the newly incoming connection to a task which does the following:</p> <ul> <li>If TLS is enabled by configuration, performs the TLS handshake (asynchronously) and split the connection into two (receiver and writer ends)</li> <li>If TLS is not needed, it just splits the connection into two (receiver and writer ends)</li> </ul> <p>The TLS handshake task spawns the reader and writer tasks and moves two proper ends of the connection to each of the task. A tokio channel is then established between the two tasks for passing data from the reader -&gt; writer task</p>"},{"location":"design/overview/#the-reader-task","title":"The reader task","text":"<p>The reader task is responsible for:</p> <ul> <li>Reading bytes from the stream</li> <li>Parsing the incoming message and constructing a <code>RedisCommand</code> structure</li> <li>Once a full command is read from the socket, it is moved to the writer task for processing</li> </ul>"},{"location":"design/overview/#the-writer-task","title":"The writer task","text":"<p>The writer task input are the commands read and constructed by the reader task.</p> <p>Once a command is received, the writer task invokes the proper handler for that command (if the command it not supported an error message is sent back to the client).</p> <p>The command handler, can return one of 2 possible actions:</p>"},{"location":"design/overview/#send-a-response-to-the-client","title":"Send a response to the client","text":"<p>There are 2 ways that the writer task can send back a response to the client:</p> <ul> <li>The command handler returns the complete response (e.g. <code>+OK\\r\\n</code>)</li> <li>The command handler writes the response directly to the socket</li> </ul> <p>The decision whether to reply directly or propagate the response to the caller task is done on per command basis. The idea is to prevent huge memory spikes where possible.</p> <p>For example, the <code>hgetall</code> command might generate a huge output (depends on the number of fields in the hash and their size) so it is probably better to write the response directly to the socket (using a controlled fixed chunks) rather than building a complete response in memory (which can take Gigabytes of RAM) and only then write it to the client.</p>"},{"location":"design/overview/#block-the-client","title":"Block the client","text":"<p>When a client executes a blocking call on a resource that is not yet available, the writer task is suspended until:</p> <ul> <li>Timeout occurrs (most blocking commands allow to specify timeout duration)</li> <li>The resource is available</li> </ul>"},{"location":"design/replication/","title":"Replication","text":""},{"location":"design/replication/#overview","title":"Overview","text":"<p><code>SableDB</code> is compatible with a <code>1</code>:<code>N</code> replication setup, where one primary server replicates to multiple secondary servers.</p>"},{"location":"design/replication/#replication-clientserver-model","title":"Replication Client/Server Model","text":"<p>Upon initialization, <code>SableDB</code> creates a thread known internally as the <code>Replicator</code>, which listens on the <code>private_address</code> (by default it is set to: main port plus <code>1000</code>).</p> <p>For each new incoming replication client, a dedicated thread is spawned to handle the connection.</p> <p>The replication process follows this methodology:</p> <ol> <li>The replica requests a set of changes from the primary starting from a specific ID (initially set to <code>0</code>).</li> <li>If this is the first request from the replica to the primary, the primary responds with an error, indicating <code>FullSyncNotDone</code>.</li> <li>The replica then sends a <code>FullSync</code> request, prompting the primary to send the entire data store.</li> <li>Subsequently, the replica sends <code>GetChanges</code> requests and applies these changes locally. Any errors on either the replica or primary side trigger a <code>FullSync</code> request.</li> <li>Step 4 repeats indefinitely; any error causes the shard to revert to <code>FullSync</code>.</li> </ol> <p>Note</p> <p>It is important to note that the primary server is stateless, meaning it does not track its replicas. The replica server is responsible for pulling data from the primary and keeping track of the next change sequence ID to pull.</p> <p>Note</p> <p>If there are no changes to send to the replica, the primary delays the response as specified in the configuration file.</p>"},{"location":"design/replication/#in-depth-overview-of-getchanges-and-fullsync-requests","title":"In-Depth Overview of <code>GetChanges</code> and <code>FullSync</code> Requests","text":"<p><code>SableDB</code> internally uses <code>RocksDB</code> APIs: <code>create_checkpoint</code> and <code>get_updates_since</code>.</p> <p>Additionally, <code>SableDB</code> maintains a file named <code>changes.seq</code> in the replica server's database folder, which stores the next transaction ID to be pulled from the primary.</p> <p>In case of any error, the replica switches to a <code>FullSync</code> request.</p> <p>The following sequence of events describes the data flow between the replica and the primary:</p> <p></p> <p>When a <code>FullSync</code> is required, the flow changes to:</p> <p></p>"},{"location":"design/replication/#replication-client","title":"Replication Client","text":"<p>The replication instance of <code>SableDB</code> operates in <code>read-only</code> mode, meaning it does not allow the execution of any commands marked as <code>Write</code>.</p>"}]}