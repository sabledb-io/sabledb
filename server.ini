[general]
# The IP on which new connections are accepted
listen_ip = 127.0.0.1

# Server listening port
port = 6379

# When running as primary, accept replicas connection on this IP. It can be different than the
# `listen_ip` (This is useful when you want to open the main IP to the world, but the
# replication IP is used internally inside a VPC)
replication_listen_ip = 127.0.0.1

# Server workers count. set to 0 to let sabledb decide
workers = 0

# Log verbosity (can be one of: info, warn, error, trace, debug)
log_level = info

# Path to the storage directory
db_path = "sabledb.db"

# path to locate / write configuration files
config_dir = "."

# To enable TLS based communication, set here the path to the certificate + the key
# cert = ssl/sabledb.crt
# key = ssl/sabledb.key

[cron]
# Evict orphan records every `purge_zombie_records_secs` seconds
# An orphan record is a record no longer accessible by the user (i.e. hash field that the parent
# hash key was overrode by a string key)
evict_orphan_records_secs = 3600

# Scan the database for statistics purposes every `scan_keys_secs` seconds
scan_keys_secs = 30

# Delete is O(1) for simple key (e.g. string key). However, for types with children (e.g. hash)
# the deletion process requires O(N+1) where N is the number of children. Some types, (e.g. sorted set)
# require O(2xN + 1). By setting this flag to `true`, SableDb will only delete the primary key (i.e. the
# is no longer accessible by the user), the remaining type children will be deleted by the eviction task
# using a background thread
instant_delete = true

[client_limits]
# Build up to `response_buffer_size` bytes in memory before flushing
# to the network
client_response_buffer_size = 1MB

[replication_limits]
# Limit the size of a single replication update message
# in memory before sending it over the network
single_update_buffer_size = 50MB

# A single replication response can hold up to `num_updates_per_message`
# database updates
num_updates_per_message = 1M

# If there are changes queued for replication, they are sent immediately.
# However, when there are no changes to send to the replica, the replication task
# suspend itself for `check_for_updates_interval_ms` milliseconds.
check_for_updates_interval_ms = 10
    
[rocksdb]
# If true, writes will not first go to the write ahead log ("WAL"),
# and the write may get lost after a crash.
# IMPORTANT: setting this value to `true` will get you performance
# improvement but will also cause to lose of data incase of crash
disable_wal = false

# Enable data compression using Snappy
compression_enabled = true

# Each write goes through a memtable which is backed by a WAL file.
# Once the memtable is full, it is marked as "immutable" and a new
# memtable is created. This directive sets the size of the memtable
write_buffer_size = 50MB

# Number of IO threads available for RocksDb to perform flush & compaction
max_background_jobs = 8

# Sets the maximum number of write buffers that are built up in memory.
# The default is 4, so that when 1 write buffer
# is being flushed to storage, new writes can continue to the other
# write buffer.
max_write_buffer_number = 4

# If "wal_ttl_seconds" is not 0, then
# WAL files will be checked every `wal_ttl_seconds / 2` and those that
# are older than `wal_ttl_seconds` will be deleted.
wal_ttl_seconds = 3600

# By default, RocksDb check whether WAL flush is needed after each write
# This option disables this and moves it to a "time based" WAL flush
#
# This is a good tradeoff between persistency and performance (if you are
# willing to lose data that were not flushed to disk in the last 
# `manual_wal_flush_interval_ms` milliseconds.)
manual_wal_flush = true

# If `manual_wal_flush` is true, SableDb will flush the wal every `N` milliseconds
manual_wal_flush_interval_ms = 500

# Sets the number of open files that can be used by the DB. You may need to
# increase this if your database has a large working set. Value `-1` means
# files opened are always kept open. You can estimate number of files based
# on target_file_size_base and target_file_size_multiplier for level-based
# compaction. For universal-style compaction, you can usually set it to `-1`.
max_open_files = -1
